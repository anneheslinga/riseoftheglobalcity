#Code should be performed in the following order.

#Install R packages
library(tidyr)
library(tidyselect)
library(tidytext)
library(tidyverse)
library(tokenizers)
library(dplyr)
library(tm)
library(syuzhet)


#Convert your data into a character vector

reviews <- restaurant_reviews_rotterdam %>%
    group_by(cuisine) %>%
    mutate(linenumber = row_number(),
           text = `full review`) %>%
    ungroup()

reviews

#Tidying the reviews or a creating one-token-per-row format

library(tidytext)

reviews <- reviews %>%
  unnest_tokens(word, text)

reviews

#Clean your text by removing stop words

data(stop_words)
reviews <- reviews %>%
  anti_join(stop_words)
 
 
#Separate your data by cuisine type

it_reviews <- reviews %>%
filter(cuisine == "italian")

cn_reviews <- reviews %>%
filter(cuisine == "chinese")
   

#Perform a word count on your text data

it_reviews %>%
  count(word, sort = TRUE)
  
#Creating a wordplot of the words most frequently used in reviews of italian restaurants

library(ggplot2)

it_reviews %>%
  count(word, sort = TRUE) %>%
  filter(n > 200) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
  
#Creating a wordplot of the words most frequently used in reviews of chinese restaurants

cn_reviews %>%
  count(word, sort = TRUE) %>%
  filter(n > 50) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
  
  
#Creating a wordcloud of most frequently used words. What words in this wordcloud stick out to you?
  
library(wordcloud)

it_reviews %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 70))

#Now create a wordcloud for chinese restaurants by replacing 'it_reviews' with 'cn_reviews'
#Don't forget to save the image of your wordclouds!

#You've just performed a basic task in text analysis! Word frequency can tell you a lot about a text.
  
#Now on to Sentiment analysis
  
#Retreive a word count for words connoting "joy" using the NRC Lexicon

nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

it_reviews %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)
  
#Retreive a word count for words connoting "disgust" using the NRC Lexicon

nrc_disgust <- get_sentiments("nrc") %>% 
  filter(sentiment == "disgust")

it_reviews %>%
  inner_join(nrc_disgust) %>%
  count(word, sort = TRUE)
  
 
#Plot positive and negative emotions by creating an index with the Bing lexicon

#Create the index
library(tidyr)

review_sentiments <- reviews %>%
  inner_join(get_sentiments("bing")) %>%
  count(cuisine, index = linenumber %/% 5, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
 
#And plot the reviews data frame

library(ggplot2)

ggplot(review_sentiments, aes(index, sentiment, fill = cuisine)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~cuisine, ncol = 2, scales = "free_x")
  
  
#Now plot trust using the NRC lexicon


it_sentiments <- it_reviews %>%
  inner_join(get_sentiments("nrc")) %>%
  count(Source, index = linenumber %/% 5, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = trust)
 
 
 ggplot(it_sentiments, aes(index, sentiment, fill = cuisine)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~cuisine, ncol = 2, scales = "free_x")
  

#That's all for sentiment analysis!

 
