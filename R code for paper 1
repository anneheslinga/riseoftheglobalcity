#Download R packages from CRAN. Be sure that you are connected to the internet for this step.

install.packages("tidyr")
install.packages("tidyselect")
install.packages("tidytext")
install.packages("tidyverse")
install.packages("tokenizers")
install.packages("dplyr")
install.packages("ggplot2")
install.packages("readxl")
install.packages("wordcloud")
install.packages("scale")
install.packages("devtools")
install.packages("remotes")

#Load R packages
library(tidyr)
library(tidyselect)
library(tidytext)
library(tidyverse)
library(tokenizers)
library(dplyr)
library(ggplot2)
library(readxl)
library(wordcloud)
library(scale)
library(devtools)
library(remotes)

#Convert your data into a character vector. Use your own file name in place of 'insert_your_file_name'.

reviews <- insert_your_file_name %>%
    group_by(cuisine) %>%
    mutate(linenumber = row_number(),
           text = `full review`) %>%
    ungroup()

reviews

#Tidying the reviews or a creating one-token-per-row format

library(tidytext)

reviews <- reviews %>%
  unnest_tokens(word, text)

reviews

#Clean your text by removing stop words

data(stop_words)
reviews <- reviews %>%
  anti_join(stop_words)
   

#Perform a word count on your text data

reviews %>%
  count(word, sort = TRUE)
  
#Creating a wordplot of the words most frequently used in the reviews. You can change the number of words the appear by increasing or decreasing the number in "filter(n > 200)"

library(ggplot2)

reviews %>%
  count(word, sort = TRUE) %>%
  filter(n > 200) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
  
  
#Creating a wordcloud of most frequently used words. You can change the number of words that appear in the wordcloud by changing "max.words = 70"
  
library(wordcloud)

reviews %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 70))


#You've just performed a basic task in text analysis! Word frequency can tell you a lot about a text.

#Now on to Sentiment analysis
  
#Retreive a word count for words connoting "joy" using the NRC Lexicon

nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

reviews %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)
  
#Retreive a word count for words connoting "disgust" using the NRC Lexicon

nrc_disgust <- get_sentiments("nrc") %>% 
  filter(sentiment == "disgust")

reviews %>%
  inner_join(nrc_disgust) %>%
  count(word, sort = TRUE)
  
  
#Plot word counts for joy (you can only do this once you hae created a character vector for a sentiment, as we did for joy and disgust in the previous two steps).
#Change the number in the filter() function to plot more or less words.

reviews %>%
    inner_join(nrc_joy) %>%
    count(word, sort = TRUE) %>%
    filter(n > 50) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip()

 
#Plot positive and negative emotions over time by creating an index with the Bing lexicon

#Create the index
library(tidyr)

review_sentiments <- reviews %>%
  inner_join(get_sentiments("bing")) %>%
  count(cuisine, index = linenumber %/% 5, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
 
#And plot the reviews data frame

library(ggplot2)

ggplot(review_sentiments, aes(index, sentiment, fill = cuisine)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~cuisine, ncol = 2, scales = "free_x")
  
  
#Now plot disgust using the NRC lexicon

review_sentiments_trust <- reviews %>%
  inner_join(get_sentiments("nrc")) %>%
  count(cuisine, index = linenumber %/% 5, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = disgust)
 
 ggplot(review_sentiments_trust, aes(index, sentiment, fill = cuisine)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~cuisine, ncol = 2, scales = "free_x")
  

#That's all for sentiment analysis!
